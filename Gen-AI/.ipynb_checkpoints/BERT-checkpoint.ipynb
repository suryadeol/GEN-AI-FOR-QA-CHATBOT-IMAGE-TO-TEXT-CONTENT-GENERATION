{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2568a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/config.json\n",
      "data/pytorch_model.bin\n",
      "data/special_tokens_map.json\n",
      "data/tokenizer_config.json\n",
      "data/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bf16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text=\"\"\"\n",
    "Cyclone Amphan\n",
    "\n",
    "Cyclone Amphan was the costliest and most powerful tropical cyclone to affect India in recent history. It made landfall on May 20, 2020, on the coast of West Bengal.\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "Category: Super Cyclonic Storm (equivalent to Category 5 hurricane)\n",
    "Maximum sustained wind speed: 240-250 km/h (150-155 mph)\n",
    "Storm surge: Up to 5 meters (16 feet)\n",
    "Impacts:\n",
    "\n",
    "West Bengal: Amphan caused widespread devastation in West Bengal, particularly in the districts of South 24 Parganas, North 24 Parganas, and Kolkata. Strong winds and heavy rains uprooted trees, damaged buildings, and destroyed thousands of homes. The storm surge caused severe flooding in coastal areas, inundating villages and displacing residents.\n",
    "Odisha: Amphan also impacted Odisha, causing damage to infrastructure and agriculture. Heavy rains led to flooding in several districts.\n",
    "Bangladesh: Amphan made landfall in Bangladesh as a Category 1 hurricane, causing widespread flooding and damage in the southern part of the country.\n",
    "Casualties and Damages:\n",
    "\n",
    "Fatalities: Over 100 people were killed in India and Bangladesh.\n",
    "Economic losses: Amphan caused an estimated $15 billion in damages in India alone, making it the costliest cyclone in the country's history.\n",
    "Infrastructure damage: The storm destroyed roads, bridges, power lines, and communication networks.\n",
    "Agriculture losses: Amphan devastated crops and livestock, particularly in West Bengal and Odisha.\n",
    "Response and Recovery:\n",
    "\n",
    "Government response: The Indian government launched a massive relief and recovery operation, deploying personnel, supplies, and resources to affected areas.\n",
    "International assistance: Several countries, including the United States, China, and the United Arab Emirates, provided humanitarian aid and support to India and Bangladesh.\n",
    "Recovery efforts: The recovery process took several months, with efforts focusing on rebuilding infrastructure, restoring livelihoods, and providing support to affected communities.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28eba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question= \"what is the height of strom surge?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ba19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained(r'data/')\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(r'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31314d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_special': True} not recognized.\n",
      "Keyword arguments {'add_special': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query has 386 tokens.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "\n",
    "encoded_dict = tokenizer.encode_plus(text=question,text_pair=answer_text, add_special=True)\n",
    "    \n",
    "    \n",
    "# Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "input_ids = encoded_dict['input_ids']\n",
    "\n",
    "# Report how long the input sequence is.\n",
    "print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "# Segment Ids\n",
    "segment_ids = encoded_dict['token_type_ids']\n",
    "\n",
    "# evaluate\n",
    "output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "\n",
    "# Find the tokens with the highest `start` and `end` scores.\n",
    "answer_start = torch.argmax(output['start_logits'])\n",
    "answer_end = torch.argmax(output['end_logits'])\n",
    "\n",
    "# Get the string versions of the input tokens.\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "\n",
    "# Start with the first token.\n",
    "answer = tokens[answer_start]\n",
    "\n",
    "# Select the remaining answer tokens and join them with whitespace.\n",
    "for i in range(answer_start + 1, answer_end + 1):\n",
    "\n",
    "    # If it's a subword token, then recombine it with the previous token.\n",
    "    if tokens[i][0:2] == '##':\n",
    "        answer += tokens[i][2:]\n",
    "\n",
    "    # Otherwise, add a space then the token.\n",
    "    else:\n",
    "        answer += ' ' + tokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a984e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \"5 meters ( 16 feet )\"\n"
     ]
    }
   ],
   "source": [
    "print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81053307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
